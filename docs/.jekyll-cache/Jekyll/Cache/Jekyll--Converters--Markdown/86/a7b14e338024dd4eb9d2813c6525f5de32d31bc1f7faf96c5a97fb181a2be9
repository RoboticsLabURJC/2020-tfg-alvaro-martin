I"¾<h2 id="new-data-type">New data type</h2>
<p>After making a learning with simpler data and see that the performance is good we decided to complicate things to the network. For this I have established a new type of movements in space for the white point of the frames: linear movement which will combine with the URM movement in time.</p>

<p>In the following <a href="https://roboticslaburjc.github.io/2017-tfm-nuria-oyaga/data/datasets/">link</a> you can find a description of this new type of images.</p>

<p>The way to obtain these new frames is the same as before, we set the position in x by means of a URM movement but this time, instead of maintaining the height of the object (position y) constant, we will modify it according to a function.</p>

<p>The problem that we can find in this type of samples is that we are modifying the height, a value that must be integer, by means of a function that accepts decimal values, which causes a rounding to be necessary. Depending on the sample, this rounding can make the movement not seem as natural as it would be because it is possible that the height does not change from one instant to the next.</p>

<h2 id="non-recurrent-neural-networks">Non Recurrent Neural Networks</h2>
<p>First we do the training of non-recucurrent networks with the new type of data to check the scope they give us.</p>

<p>As in the URM case, I started training a 2D convolutional network whose structure can be seen in the following figure:</p>
<figure class="">
  <img src="/assets/images/logbook/media/Models/Non-Recurrent/Frame_point_linear/1000_samples/2_False_relu_categorical_crossentropy_10_properties.png" alt="2D Convolutional network structure" />
  </figure>

<p>As in the two previous cases, the network manages to reduce and stabilize the loss function in only a few epochs but, because the sequences begin to get more complicated, this network is not able to capture 100% of the different movements.</p>
<figure class="">
  <img src="/assets/images/logbook/media/Models/Non-Recurrent/Frame_point_linear/1000_samples/2_False_relu_categorical_crossentropy_10_history.png" alt="Loss history" />
  </figure>

<figure class="">
  <img src="/assets/images/logbook/media/Models/Non-Recurrent/Frame_point_linear/1000_samples/2_False_relu_categorical_crossentropy_10_error_hist.png" alt="Relative error histogram" />
  </figure>

<p>In the next image you can see target frame in the samples where the errors (absolute and relative) are maximum. As we commented previously, the error committed is not null, although the maximum error committed is quite small.</p>
<figure class="">
  <img src="/assets/images/logbook/media/Models/Non-Recurrent/Frame_point_linear/1000_samples/2_False_relu_categorical_crossentropy_10_max_error.png" alt="Relative and absolute error" />
  </figure>

<h2 id="more-samples">More samples</h2>
<p>To try to improve performance we tried to increase the number of samples, according to the complexity of the data, to be able to cover more examples and get the network to improve its learning. I used 5000 samples instead of 1000 and the same structure.</p>

<p>As the number of samples increases, the performance of the network improves and a greater stabilization of the same is achieved in the training.</p>
<figure class="">
  <img src="/assets/images/logbook/media/Models/Non-Recurrent/Frame_point_linear/5000_samples/15_False_relu_categorical_crossentropy_10_history.png" alt="Loss history" />
  </figure>

<figure class="">
  <img src="/assets/images/logbook/media/Models/Non-Recurrent/Frame_point_linear/5000_samples/15_False_relu_categorical_crossentropy_10_error_hist.png" alt="Error histogram" />
  </figure>

<figure class="">
  <img src="/assets/images/logbook/media/Models/Non-Recurrent/Frame_point_linear/5000_samples/15_False_relu_categorical_crossentropy_10_rel_error_hist.png" alt="Relative error histogram" />
  </figure>

<p>In the next image you can see target frame in the samples where the errors (absolute and relative) are maximum. As in the case with less samples, the error committed is not null, although the maximum error committed is quite small. In addition, despite the fact that the maximum error is the same, the average error has decreased with increasing number of samples.</p>
<figure class="">
  <img src="/assets/images/logbook/media/Models/Non-Recurrent/Frame_point_linear/5000_samples/15_False_relu_categorical_crossentropy_10_max_error.png" alt="Relative and absolute error" />
  </figure>

<h2 id="recurrent-neural-networks">Recurrent Neural Networks</h2>
<p>The performance obtained with the previous network can still be improved improved, so we chose to include the recurrent networks to try to improve it. I have used the following structure:</p>
<figure class="">
  <img src="/assets/images/logbook/media/Models/Recurrent/Frames/linear_point_255/LSTM/15_False_relu_categorical_crossentropy_10_properties.png" alt="Conv + LSTM network structure" />
  </figure>

<p>With the proposed structure the performance is not good and the error is very high.</p>
<figure class="">
  <img src="/assets/images/logbook/media/Models/Recurrent/Frames/linear_point_255/LSTM/15_False_relu_categorical_crossentropy_10_history.png" alt="Loss history" />
  </figure>

<figure class="">
  <img src="/assets/images/logbook/media/Models/Recurrent/Frames/linear_point_255/LSTM/15_False_relu_categorical_crossentropy_10_error_hist.png" alt="Error histogram" />
  </figure>

<figure class="">
  <img src="/assets/images/logbook/media/Models/Recurrent/Frames/linear_point_255/LSTM/15_False_relu_categorical_crossentropy_10_rel_error_hist.png" alt="Relative error histogram" />
  </figure>

<p>In the next image you can see target frame in the samples where the errors (absolute and relative) are maximum. As I mentioned earlier, the error made with this network is excessively high.</p>
<figure class="">
  <img src="/assets/images/logbook/media/Models/Recurrent/Frames/linear_point_255/LSTM/15_False_relu_categorical_crossentropy_10_max_error.png" alt="Relative and absolute error " />
  </figure>

<h2 id="recurrent-neural-networks---new-structure">Recurrent Neural Networks - New structure</h2>
<p>In view of the results obtained previously I have replaced the simple LSTM layer with a ConvLSTM which computes convolutional operations in both the input and the recurrent transformations. The new structure is as follows:</p>
<figure class="">
  <img src="/assets/images/logbook/media/Models/Recurrent/Frames/linear_point_255_y0/15_False_relu_categorical_crossentropy_10_properties.png" alt="ConvLSTM network structure" />
  </figure>

<p>With the new structure the performance of the network is improved and the results are practically the same as in the non-recurrent case that were pretty good</p>
<figure class="">
  <img src="/assets/images/logbook/media/Models/Recurrent/Frames/linear_point_255/ConvLSTM/15_False_relu_categorical_crossentropy_10_history.png" alt="Loss history" />
  </figure>

<figure class="">
  <img src="/assets/images/logbook/media/Models/Recurrent/Frames/linear_point_255/ConvLSTM/15_False_relu_categorical_crossentropy_10_error_hist.png" alt="Error histogram" />
  </figure>

<figure class="">
  <img src="/assets/images/logbook/media/Models/Recurrent/Frames/linear_point_255/ConvLSTM/15_False_relu_categorical_crossentropy_10_rel_error_hist.png" alt="Relative error histogram" />
  </figure>

<p>In the next image you can see target frame in the samples where the errors (absolute and relative) are maximum. The maximum error committed coincides with the non-recurrent case and in terms of the average a very similar result is obtained.</p>
<figure class="">
  <img src="/assets/images/logbook/media/Models/Recurrent/Frames/linear_point_255/ConvLSTM/15_False_relu_categorical_crossentropy_10_max_error.png" alt="Relative and absolute error" />
  </figure>

:ET